{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import plotly.express as px\n",
    "import math\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('../output_data/TrainingDatasetCustomer v1.csv', sep=';')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "positive_feature_names = [\n",
    "    'ContractAmountAll',\n",
    "    'ContractsCount',\n",
    "    'ProceduresCount',\n",
    "    'customer_max_price',\n",
    "]\n",
    "negative_feature_names = [\n",
    "    'SuspiciousFactsCount',\n",
    "    'ContractAmountBad',\n",
    "    'ContractsCountBad',\n",
    "    'BadNewsCount',\n",
    "    'ContractCountTerminationByCourt',\n",
    "    'ContractCountTerminationByCustomer',\n",
    "    'ContractCountTerminationBySupplier',\n",
    "    'ComplaintsCount',\n",
    "]\n",
    "feature_names = positive_feature_names + negative_feature_names\n",
    "\n",
    "rows = df.sample(frac=1)\n",
    "\n",
    "labels = rows[['inn']]\n",
    "\n",
    "features_default = pd.Series(np.zeros(len(feature_names)).fill(np.nan), index=feature_names, dtype='float64')\n",
    "\n",
    "for feature_name in feature_names:\n",
    "    rows[[feature_name]] = rows[[feature_name]].fillna(features_default[feature_name])\n",
    "rows = rows.dropna()\n",
    "\n",
    "features = rows[feature_names].copy()\n",
    "\n",
    "features_weight = pd.Series(np.ones(len(feature_names)), index=feature_names, dtype='float64')\n",
    "features_weight[negative_feature_names] = -1\n",
    "\n",
    "features_mean = features.mean()\n",
    "\n",
    "features_std = features.std()\n",
    "\n",
    "features_norm = (features - features_mean) / features_std\n",
    "\n",
    "features_params = pd.DataFrame({\n",
    "    'default': features_default,\n",
    "    'mean': features_mean,\n",
    "    'std': features_std,\n",
    "    'weight': features_weight,\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "# @REFERENCE: https://github.com/python/cpython/issues/98363#issue-1411970397\n",
    "def batched(iterable, n):\n",
    "    if n < 1:\n",
    "        raise ValueError('n must be >= 1')\n",
    "    it = iter(iterable)\n",
    "    while (batch := list(islice(it, n))):\n",
    "        yield batch\n",
    "\n",
    "wins = pd.DataFrame({'Wins': 0}, index=features.index)\n",
    "\n",
    "for feature_name in feature_names:\n",
    "    feature = features_norm[feature_name].values\n",
    "    for batch in batched(feature, 500): # @NOTE: Чтобы не держать все в памяти одновременно\n",
    "        matrix = (feature[:, None] >= batch[:])\n",
    "        wins['Wins'] += features_weight[feature_name] * np.count_nonzero(matrix, axis=1)\n",
    "\n",
    "# tmp\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "wins['Wins'] = sigmoid((wins['Wins'] - wins['Wins'].mean()) / wins['Wins'].std())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features_train, features_test, wins_train, wins_test = train_test_split(features_norm, wins, test_size = 0.1)\n",
    "features_train, features_val, wins_train, wins_val = train_test_split(features_train, wins_train, test_size = 0.2)\n",
    "\n",
    "print(f\"Feature shape: {features_train.shape}\")\n",
    "print(f\"Training = {len(features_train)}, validation = {len(features_val)}, test = {len(features_test)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.Input(shape=(features_train.shape[1])),\n",
    "    keras.layers.Dense(20, activation=\"relu\", activity_regularizer=keras.regularizers.L1L2(0.000001)),\n",
    "    keras.layers.Dense(15, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"relu\"),\n",
    "    keras.layers.Dense(5, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer='adamax')\n",
    "initial_loss = model.evaluate(features_train, wins_train)\n",
    "initial_val_loss = model.evaluate(features_val, wins_val)\n",
    "history = pd.DataFrame(dict(\n",
    "    time=[0],\n",
    "    loss=[initial_loss],\n",
    "    val_loss=[initial_val_loss],\n",
    "    batch_size=[math.nan],\n",
    "))\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils.time_callback import TimeCallback\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 500\n",
    "\n",
    "time_callback = TimeCallback()\n",
    "hist = model.fit(features_train, wins_train, batch_size=batch_size, epochs=epochs, validation_data=(features_val, wins_val), callbacks=[time_callback])\n",
    "history_chunk = pd.merge(\n",
    "    pd.DataFrame(hist.history),\n",
    "    pd.DataFrame(dict(time=time_callback.times, batch_size=batch_size)),\n",
    "    left_index=True, right_index=True,\n",
    ")\n",
    "history = pd.concat((history, history_chunk), ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "px.line(history, y=['loss', 'val_loss'], log_y=True, log_x=True).show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wins_predicted = pd.DataFrame(model.predict(features_norm), columns=['Wins Predicted'], index=features.index)\n",
    "tmp = features.join(wins).join(wins_predicted).join(labels)\n",
    "\n",
    "# px.scatter(tmp, x=\"Wins\", y=\"Wins Predicted\", hover_name='inn')\n",
    "# px.scatter(tmp, x=\"customer_max_price\", y=\"Wins\", color='Wins Predicted', hover_name='inn', log_x=True)\n",
    "px.scatter(tmp, x=\"ContractAmountAll\", y=\"ContractAmountBad\", color='Wins Predicted', hover_name='inn', log_x=True, log_y=True)\n",
    "# px.scatter(tmp, x=\"AltmanIndex\", y=\"ContractAmountBad\", color='Wins Predicted', hover_name='inn', log_y=True)\n",
    "# px.scatter(tmp, x=\"win_qty44\", y=\"win_qty223\", color='Wins Predicted', hover_name='inn', log_x=True, log_y=True)\n",
    "\n",
    "# px.histogram(wins_predicted.sample(10000), log_y=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SAVE_MODEL_PATH = f'../models/customer'\n",
    "\n",
    "model.save(f'{SAVE_MODEL_PATH}/model')\n",
    "features_params.to_csv(f'{SAVE_MODEL_PATH}/features_params.csv')\n",
    "history.to_csv(f'{SAVE_MODEL_PATH}/history.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
